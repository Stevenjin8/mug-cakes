While we can express our beliefs about our objective function $f$
using a Gaussian Process $F \sim \mathcal{GP}(m, \kappa_{\rbf})$,
acquisition functions balances exploration and exploitation
by picking where to evaluate $f$ at every iteration.
Unlike Gaussian Processes, acquisition functions are usually heuristics-based.
In this section, we focus on a variation of Expected Improvement (EI).

Under EI, the utility of evaluating $f(\mathbf{x})$ is the expectation of the maximum sampled $y$-value after the $N$th iteration.
\begin{align}
    \label{eq:ei}
    a_{\mathrm{EI}}(\mathbf{x} | \mathcal{D}_N) &= \mathbb{E}[\max\{F(\mathbf{x}), y_1, \dots, y_N\} | \mathcal{D}_N] \\
    & = y_* + \mathbb{E}[\max\{F(\mathbf{x}) - y_*, 0\} |\mathcal{D}_N] \\
    & = y_* + \mathbb{E}[F(\mathbf{x}) - y_* | F(\mathbf{x}) > y_*, \mathcal{D}_N]p(F(\mathbf{x}) > y_* | \mathcal{D}_N)
\end{align}
where $y_* = \max\{y_1, \dots, y_N\}$.
EI encourages both exploitation and exploration because $F(\mathbf{x})$ will probably be greater than $y_*$ only if we are very uncertain about $F(\mathbf{x})$ (exploration) or we think $F(\mathbf{x})$ is near $y_*$ (exploitation).

However, the usage of $y_*$ in Equation~\ref{eq:ei} makes little sense if we have noisy observations because $y_*$'s extremity could be due to noise.
It makes less sense if we consider biased observations because $y_*$ is even less representative of the underlying function and we are not using our knowledge about each observer's bias.
The following definition addresses this issue by replacing $y_*$ with $F(x_*)$.

\begin{definition}[vEI]
    \begin{align*}
        \begin{split}
        \label{eq:vei}
        a_{\vei}(\mathbf{x} | \mathcal{D}_N) &= \mathbb{E}[\max \{ F(\mathbf{x}), F(\mathbf{x}_*) \} | \mathcal{D}_N] \\
        &= \mathbb{E}[F(\mathbf{x}_*) | \mathcal{D}_N] + \mathbb{E}[\max \{ F(\mathbf{x}) - F(\mathbf{x}_*), 0 \} | \mathcal{D}_N]
        \end{split}
    \end{align*}
    where $\mathbf{x}_* = \argmax_{\mathbf{x'} \in (\mathbf{x}_1, \dots, \mathbf{x}_N)} \mathbb{E}[F(\mathbf{x'}) | \mathcal{D}_N]$.
\end{definition}

The big difference between vEI and EI is that while $y_*$ in Equation~\ref{eq:ei} is a constant, $F(\mathbf{x}_*)$ in Equation~\ref{eq:vei} is a random variable.
Thus, we need to take into account the dependence between $F(\mathbf{x})$ and $F(\mathbf{x}_*)$.
In practice this dependence encourages exploration because $F(\mathbf{x}) - F(\mathbf{x}_*)$ will probably be small when $\mathbf{x}$ and $\mathbf{x}_*$ are similar as seen in Figure~\ref{fig:ei};
even though our posterior mean is maximized at 0.8, vEI is maximized at 0.25 because 0.25 is further away from $\mathbf{x}_* = 0.75$ than 0.8.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{fig/ei.png}
    \caption{
        The top figure shows the posterior of a Gaussian Process with a mean function of 0,
        $\sigma_{\epsilon}^2 = 0.2^2$, and RBF kernel.
        The kernel parameters were $\sigma_f^2 = 0.5^2, \ell^2 = 0.2^2$.
        The grey area is the 95\% posterior credible interval and the dotted line is the posterior mean.
        The points are noisy, but unbiased observations, and the dotted vertical red line represents the sampled $\mathbf{x}$-value with the highest posterior mean.
        The bottom figure shows $a_\vei$ given the data and the surrogate model from the top figure.
    }
    \label{fig:ei}

\end{figure}

Because $F(\mathbf{x})$ and $F(\mathbf{x}_*)$ are jointly Gaussian for all $\mathbf{x}, \mathbf{x}^{*} \in \mathcal{X}$, we can find vEI in closed form.
Let $\varphi$ and $\Phi$ be the pdf and cdf of the standard univariate normal respectively.
Because $F$ is a Gaussian Process,
\begin{equation*}
    \begin{bmatrix}
        F(\mathbf{x}) \\
        F(\mathbf{x}_*)
    \end{bmatrix}
    \bigg| \mathcal{D}_N
    \sim \mathcal{N}\left(
    \begin{bmatrix}
            \mu_1 \\
            \mu_2
        \end{bmatrix}
    ,
    \begin{bmatrix}
            \sigma_{1}^2 & \sigma_{12} \\
            \sigma_{21} & \sigma^2_2
        \end{bmatrix}
    \right)
\end{equation*}
for some $\mu_1, \mu_2, \sigma_{12} \in \mathbb{R}$ and $\sigma_1, \sigma_2 > 0$ by our discussion in Section~\ref{sssec:post-inf}.
Setting $\mu = \mu_1 - \mu_2$ and $\sigma^2 = \sigma_1^2 + \sigma_2^2 - 2 \sigma_{12}$,
\begin{equation*}
    F(\mathbf{x}) - F\left(\mathbf{x}_*\right) \sim \mathcal{N}(\mu_1 - \mu_2, \sigma_1^2 + \sigma_2^2 - 2\sigma_{12})
    = \mathcal{N}\left(\mu, \sigma^2\right)
\end{equation*}
by Theorem~\ref{thm:ogag}.
It follows that
\begin{align*}
    a_{\vei}(\mathbf{x} | \mathcal{D}_N)
    & =  \mathbb{E}[F(\mathbf{x}_*) + \max \{  F(\mathbf{x}) - F(\mathbf{x}_*), 0 \} | \mathcal{D}_N] \\
    & = \mu_2 + \int_{0}^\infty u \frac{ 1 }{ \sqrt{2 \pi } \sigma} \exp \left\{ -\frac12 \left(\frac{ u - \mu }{ \sigma }\right)^2 \right\} \dd u \\
    & = \mu_2 + \int_{0}^\infty u \frac{ 1 }{ \sigma } \varphi\left(\frac{ u - \mu }{ \sigma }\right) \dd u \\
    & = \mu_2 + \left[ \mu \Phi\left(\frac{ u - \mu }{ \sigma }\right) - \sigma \varphi\left(\frac{ u - \mu }{ \sigma }\right)\right]_{0}^{\infty} \\
    & = \mu_2 +  \mu - \mu \Phi\left(\frac{ -\mu }{ \sigma }\right) + \sigma \varphi\left(\frac{ -\mu }{ \sigma }\right) \\
    %& = \mu_2 + \mu - \mu\left( 1 - \Phi\left(\frac{ \mu }{ \sigma }\right)\right) + \sigma\varphi\left(\frac{ \mu }{ \sigma }\right) \\
    & = \mu_2 + \mu \Phi\left(\frac{ \mu }{ \sigma }\right) + \sigma \varphi\left(\frac{ \mu }{ \sigma }\right).
\end{align*}
We evaluated the integral using the fact that
\begin{equation*}
    \frac{ \dd }{ \dd u } \varphi(u) = - u\varphi(u)
    \text{  and  }
    \frac{ \dd }{ \dd u } \Phi(u) = \varphi(u)
\end{equation*}
meaning that
\begin{equation*}
    \frac{ \dd }{ \dd u }
    \left[
        \mu \Phi\left(\frac{ u - \mu }{ \sigma }\right) - \sigma \varphi\left(\frac{ u - \mu }{ \sigma }\right)
        \right]
    = u \frac{ 1 }{ \sigma } \varphi\left( \frac{ u - \mu }{\sigma}\right).
\end{equation*}

Because of the usage of $\Phi$, it is hard to maximize $a_{\vei}$ it analytically.
At the same time, we can see in Figure~\ref{fig:ei} that $a_{\vei}$ can have many local maxima.
Thus, we have to rely on global optimization methods such as Basin Hopping \cite{wales1997} to find where to evaluate $f$ at each iteration.
